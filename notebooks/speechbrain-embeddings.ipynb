{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f599c1",
   "metadata": {},
   "source": [
    "# Извлечение голосовых эмбеддингов\n",
    "## Speechbrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bdee9",
   "metadata": {},
   "source": [
    "Указываем путь до датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6458f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_DIR = 'C:/Maksim/diploma/dataset'\n",
    "\n",
    "speakers = os.listdir(DATASET_DIR)\n",
    "\n",
    "print(len(speakers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26d3ca",
   "metadata": {},
   "source": [
    "## Модель-эмбеддер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304eedf9",
   "metadata": {},
   "source": [
    "Базовый класс-интерфейс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228e96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SpeakerEmbedder(metaclass=ABCMeta):\n",
    "  @abstractmethod\n",
    "  def __call__(self, audio_path: str) -> np.ndarray:\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AudioData:\n",
    "  speaker: str = field(repr=True)\n",
    "  name: str = field(repr=True)\n",
    "  embedding: list[float] = field(repr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3808cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "\n",
    "class EcapaEmbedder(SpeakerEmbedder):\n",
    "  def __init__(self, device: str = 'cpu'):\n",
    "    super().__init__()\n",
    "    self.model = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\":device})\n",
    "\n",
    "\n",
    "  def __call__(self, audio_path: str) -> np.ndarray:\n",
    "    signal, sr = torchaudio.load(audio_path)\n",
    "\n",
    "    signal = Resample(sr, 16000)(signal)\n",
    "\n",
    "    embedding = self.model.encode_batch(signal)[0][0].cpu().tolist()\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6727611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class DatasetEmbedder:\n",
    "  def __init__(self, embedder: SpeakerEmbedder,\n",
    "               dataset_dir: str,\n",
    "               output_file: str = './embeddings.json'):\n",
    "    self.embedder = embedder\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.speakers = os.listdir(self.dataset_dir)\n",
    "    self.output_file = output_file\n",
    "\n",
    "    self.embd_dataset: list[AudioData] = []\n",
    "\n",
    "\n",
    "  def process_speaker(self, spk_dir: str):\n",
    "    spk = os.path.basename(spk_dir)\n",
    "    audios: list[str] = os.listdir(spk_dir)\n",
    "\n",
    "    for audio in audios:\n",
    "      audio_path = os.path.normpath(os.path.join(spk_dir, audio))\n",
    "      embedding = self.embedder(audio_path)\n",
    "      self.embd_dataset.append(AudioData(\n",
    "          speaker=spk,\n",
    "          name=audio,\n",
    "          embedding=embedding\n",
    "      ))\n",
    "\n",
    "  def to_json(self):\n",
    "    \"\"\"Преобразует self.embd_dataset -> json в формате:\n",
    "    {\n",
    "      \"data\": [\n",
    "        {\n",
    "          \"spk\": \"1\",\n",
    "          \"audio\": \"1.wav\",\n",
    "          \"embedding\": [...] # list[float]\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for audio_data in self.embd_dataset:\n",
    "        data_list.append({\n",
    "            \"spk\": audio_data.speaker,\n",
    "            \"audio\": audio_data.name,\n",
    "            \"embedding\": audio_data.embedding\n",
    "        })\n",
    "\n",
    "    result = {\n",
    "        \"data\": data_list\n",
    "    }\n",
    "\n",
    "    with open(self.output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "  def __call__(self) -> list[AudioData]:\n",
    "    for spk in tqdm(self.speakers, desc=\"Speakers\"):\n",
    "      spk_dir = os.path.normpath(os.path.join(self.dataset_dir, spk))\n",
    "      self.process_speaker(spk_dir)\n",
    "\n",
    "    try:\n",
    "      self.to_json()\n",
    "    except Exception as err:\n",
    "      print(f\"Ошибка при сохранении результатов в файл: {err}\")\n",
    "\n",
    "    return self.embd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debde3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embd = DatasetEmbedder(\n",
    "    embedder=EcapaEmbedder(),\n",
    "    dataset_dir=DATASET_DIR,\n",
    "    output_file='./voxtube-speakernet-embeddings.json'\n",
    ")\n",
    "\n",
    "embd_dataset = embd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechbrain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
