{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0db3e4",
   "metadata": {},
   "source": [
    "# Извлечение голосовых эмбеддингов\n",
    "## Pyannote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124fce8c",
   "metadata": {},
   "source": [
    "#### Виртуальное окружение и зависимости\n",
    "```bash\n",
    "$conda create -n pyannote-env python=3.12\n",
    "$conda activate pyannote-env\n",
    "$conda install ffmpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyannote-audio==4.0.1\n",
    "!pip install omegaconf==2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87890f",
   "metadata": {},
   "source": [
    "Версии библиотек-зависимостей:\n",
    "- torch==2.9.0\n",
    "- torchaudio==2.9.0\n",
    "- torchcodec==0.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9ae67",
   "metadata": {},
   "source": [
    "Указываем путь до датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17591ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_DIR = 'C:/Maksim/diploma/dataset'\n",
    "\n",
    "speakers = os.listdir(DATASET_DIR)\n",
    "\n",
    "print(len(speakers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438dde39",
   "metadata": {},
   "source": [
    "Задаём huggingface access token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4634678",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"<YOUR TOKEN HERE>\"\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d74bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# или используйте hugginface консоль для авторизации\n",
    "#!hf auth login <token>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dc5e8",
   "metadata": {},
   "source": [
    "## Модель-эмбеддер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f39af1",
   "metadata": {},
   "source": [
    "Базовый класс-интерфейс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad05058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SpeakerEmbedder(metaclass=ABCMeta):\n",
    "  @abstractmethod\n",
    "  def __call__(self, audio_path: str) -> np.ndarray:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AudioData:\n",
    "  speaker: str = field(repr=True)\n",
    "  name: str = field(repr=True)\n",
    "  embedding: list[float] = field(repr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a0fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maksi\\miniconda3\\envs\\pyannote-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyannote.audio import Model, Inference\n",
    "\n",
    "class PyannoteEmbedder(SpeakerEmbedder):\n",
    "    def __init__(self, device: str = \"cpu\"):\n",
    "        super().__init__()\n",
    "        model = Model.from_pretrained(\"pyannote/embedding\", use_auth_token=TOKEN)\n",
    "        self.inference = Inference(model, window=\"whole\").to(torch.device(device))\n",
    "\n",
    "    def __call__(self, audio_path: str) -> list[float]:\n",
    "        embedding = self.inference(audio_path)\n",
    "        return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580ccdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class DatasetEmbedder:\n",
    "  def __init__(self, embedder: SpeakerEmbedder,\n",
    "               dataset_dir: str,\n",
    "               output_file: str = './embeddings.json'):\n",
    "    self.embedder = embedder\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.speakers = os.listdir(self.dataset_dir)\n",
    "    self.output_file = output_file\n",
    "\n",
    "    self.embd_dataset: list[AudioData] = []\n",
    "\n",
    "\n",
    "  def process_speaker(self, spk_dir: str):\n",
    "    spk = os.path.basename(spk_dir)\n",
    "    audios: list[str] = os.listdir(spk_dir)\n",
    "\n",
    "    for audio in audios:\n",
    "      audio_path = os.path.normpath(os.path.join(spk_dir, audio))\n",
    "      embedding = self.embedder(audio_path)\n",
    "      self.embd_dataset.append(AudioData(\n",
    "          speaker=spk,\n",
    "          name=audio,\n",
    "          embedding=embedding\n",
    "      ))\n",
    "\n",
    "  def to_json(self):\n",
    "    \"\"\"Преобразует self.embd_dataset -> json в формате:\n",
    "    {\n",
    "      \"data\": [\n",
    "        {\n",
    "          \"spk\": \"1\",\n",
    "          \"audio\": \"1.wav\",\n",
    "          \"embedding\": [...] # list[float]\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for audio_data in self.embd_dataset:\n",
    "        data_list.append({\n",
    "            \"spk\": audio_data.speaker,\n",
    "            \"audio\": audio_data.name,\n",
    "            \"embedding\": audio_data.embedding\n",
    "        })\n",
    "\n",
    "    result = {\n",
    "        \"data\": data_list\n",
    "    }\n",
    "\n",
    "    with open(self.output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "  def __call__(self) -> list[AudioData]:\n",
    "    for spk in tqdm(self.speakers, desc=\"Speakers\"):\n",
    "      spk_dir = os.path.normpath(os.path.join(self.dataset_dir, spk))\n",
    "      self.process_speaker(spk_dir)\n",
    "\n",
    "    try:\n",
    "      self.to_json()\n",
    "    except Exception as err:\n",
    "      print(f\"Ошибка при сохранении результатов в файл: {err}\")\n",
    "\n",
    "    return self.embd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cd9a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maksi\\miniconda3\\envs\\pyannote-env\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:197: Redirecting import of pytorch_lightning.callbacks.early_stopping.EarlyStopping to lightning.pytorch.callbacks.early_stopping.EarlyStopping\n",
      "c:\\Users\\maksi\\miniconda3\\envs\\pyannote-env\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:197: Redirecting import of pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint to lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint\n",
      "c:\\Users\\maksi\\miniconda3\\envs\\pyannote-env\\Lib\\site-packages\\lightning\\pytorch\\utilities\\migration\\migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.6. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint C:\\Users\\maksi\\.cache\\huggingface\\hub\\models--pyannote--embedding\\snapshots\\4db4899737a38b2d618bbd74350915aa10293cb2\\pytorch_model.bin`\n",
      "c:\\Users\\maksi\\miniconda3\\envs\\pyannote-env\\Lib\\site-packages\\pyannote\\audio\\core\\model.py:636: UserWarning: Model has been trained with a task-dependent loss function. Set 'strict' to False to load the model without its loss function and prevent this warning from appearing. \n",
      "  warnings.warn(msg)\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.5.6. To apply the upgrade to your files permanently, run `python -m lightning.pytorch.utilities.upgrade_checkpoint C:\\Users\\maksi\\.cache\\huggingface\\hub\\models--pyannote--embedding\\snapshots\\4db4899737a38b2d618bbd74350915aa10293cb2\\pytorch_model.bin`\n",
      "c:\\Users\\maksi\\miniconda3\\envs\\pyannote-env\\Lib\\site-packages\\lightning\\pytorch\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['loss_func.W']\n",
      "Speakers: 100%|██████████| 785/785 [21:27<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "dataset_embedder = DatasetEmbedder(\n",
    "    embedder=PyannoteEmbedder(),\n",
    "    dataset_dir=DATASET_DIR,\n",
    "    output_file='./voxtube-pyannote-embeddings.json'\n",
    ")\n",
    "\n",
    "embd_dataset = dataset_embedder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyannote-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
